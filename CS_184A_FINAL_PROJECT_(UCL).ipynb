{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdd8366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bdd8366",
        "outputId": "d12e51ee-e7d6-4ae7-e5ab-8f2c26304a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pybaseball in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (2.2.7)\n",
            "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (1.24.3)\n",
            "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.18.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (2.31.0)\n",
            "Requirement already satisfied: lxml>=4.2.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (4.9.3)\n",
            "Requirement already satisfied: pyarrow>=1.0.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (11.0.0)\n",
            "Requirement already satisfied: pygithub>=1.51 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (2.1.1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (1.11.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (3.7.2)\n",
            "Requirement already satisfied: tqdm>=4.50.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (4.65.0)\n",
            "Requirement already satisfied: attrs>=20.3.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pybaseball) (22.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.0->pybaseball) (2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (10.0.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->pybaseball) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->pybaseball) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->pybaseball) (2023.3)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (1.5.0)\n",
            "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (4.7.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (1.26.16)\n",
            "Requirement already satisfied: Deprecated in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pygithub>=1.51->pybaseball) (1.2.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from requests>=2.18.1->pybaseball) (2023.11.17)\n",
            "Requirement already satisfied: colorama in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from tqdm>=4.50.0->pybaseball) (0.4.6)\n",
            "Requirement already satisfied: cryptography>=3.3.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->pygithub>=1.51->pybaseball) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pynacl>=1.4.0->pygithub>=1.51->pybaseball) (1.15.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pybaseball) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from Deprecated->pygithub>=1.51->pybaseball) (1.14.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from cffi>=1.4.1->pynacl>=1.4.0->pygithub>=1.51->pybaseball) (2.21)\n",
            "Requirement already satisfied: pandas in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\hanvi\\anaconda3\\lib\\site-packages (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pybaseball\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, mean_squared_error, log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pybaseball import pybaseball as pb\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import requests\n",
        "\n",
        "pb.cache.enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1649a790",
      "metadata": {
        "id": "1649a790"
      },
      "outputs": [],
      "source": [
        "def get_injury_year(date):\n",
        "  if (date == np.nan or type(date) == float):\n",
        "    return np.nan\n",
        "  if date.month < 4:\n",
        "    return date.year-1\n",
        "  return date.year\n",
        "\n",
        "def build_ucl_injuries():\n",
        "    tj = pd.read_csv(Path('tj.csv'))\n",
        "    ucl_prp = pd.read_csv(Path('ucl_prp.csv'))\n",
        "    ucl_internal = pd.read_csv(Path('ucl_internal.csv'))\n",
        "\n",
        "    def to_date_list(column):\n",
        "        return list(map(str, column.tolist()))\n",
        "\n",
        "    def list_in_date(list):\n",
        "        new_list = []\n",
        "        for item in list:\n",
        "            split = item.split('/')\n",
        "            if (split != ['nan']):\n",
        "                new_list.append(datetime.date(int(split[2]), int(split[0]), int(split[1])))\n",
        "            else:\n",
        "                new_list.append(np.nan)\n",
        "        return new_list\n",
        "\n",
        "    names = tj['Player'].tolist()\n",
        "    names += ucl_prp[ucl_prp.TJ_Surgery_Date != np.nan]['Player'].tolist()\n",
        "    names += ucl_internal[ucl_internal.TJ_Surgery_Date != np.nan]['Player'].tolist()\n",
        "    dates = to_date_list(tj['Date'])\n",
        "    dates += to_date_list(ucl_prp[ucl_prp.TJ_Surgery_Date != np.nan]['Date'])\n",
        "    dates += to_date_list(ucl_internal[ucl_internal.TJ_Surgery_Date != np.nan]['Date'])\n",
        "    dates = list_in_date(dates)\n",
        "\n",
        "    years = []\n",
        "    for date in dates:\n",
        "        years.append(get_injury_year(date))\n",
        "\n",
        "    data = {'Name': names,\n",
        "            'Date':dates,\n",
        "            'Year': years}\n",
        "\n",
        "    ucl_injuries = DataFrame(data)\n",
        "\n",
        "    ucl_injuries = ucl_injuries.drop_duplicates(subset=['Name', 'Date'], keep=False)\n",
        "    ucl_injuries = ucl_injuries.dropna()\n",
        "    ucl_injuries = ucl_injuries.sort_values(by='Date', ascending=False)\n",
        "\n",
        "    return ucl_injuries\n",
        "\n",
        "# Add injury to season totals\n",
        "def add_ucl_injuries_to_table(ucl_injuries):\n",
        "    season_tots = pb.pitching_stats(2018, 2023, qual=1)\n",
        "    ucl_injury_season = []\n",
        "    for index, row in season_tots.iterrows():\n",
        "        if len(ucl_injuries[(ucl_injuries.Name == row['Name']) & (ucl_injuries.Year == row['Season'])]) > 0:\n",
        "            ucl_injury_season.append(1)\n",
        "        else:\n",
        "            ucl_injury_season.append(0)\n",
        "    season_tots['UCL_Injury'] = ucl_injury_season\n",
        "    season_tots.to_csv(Path('season_tots.csv'))\n",
        "    return season_tots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac89e4c9",
      "metadata": {
        "id": "ac89e4c9"
      },
      "outputs": [],
      "source": [
        "import_cols_left = ['Name', 'Season', 'Age', 'G', 'GS', 'CG', 'IP', 'Pitches', 'K/BB', 'FB%', 'FBv',\n",
        "                    'SL%', 'SLv', 'CT%', 'CTv', 'CB%', 'CBv', 'CH%', 'CHv', 'SF%', 'SFv', 'KN%', 'KNv',\n",
        "                    'Zone%', 'F-Strike%', 'K%', 'BB%', 'UCL_Injury']\n",
        "import_cols_right = ['last_name, first_name', 'Year', 'ff_avg_spin', 'si_avg_spin', 'fc_avg_spin', 'sl_avg_spin',\n",
        "                     'ch_avg_spin', 'cu_avg_spin']\n",
        "\n",
        "def remove_accents(name):\n",
        "        temp = name.replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n').replace('ü', 'u').replace('Á', 'A')\n",
        "        return temp.replace('É', 'E').replace('Í', 'I').replace('Ó', 'O').replace('Ú', 'U').replace('Ñ', 'N').replace('Ü', 'U')\n",
        "\n",
        "def fix_name(name):\n",
        "  split = name.split(', ')\n",
        "  return remove_accents(split[1]) + ' ' + remove_accents(split[0])\n",
        "\n",
        "def get_spin():\n",
        "  output = None\n",
        "  for i in range(2018, 2024):\n",
        "    statcast = pb.statcast_pitcher_pitch_arsenal(i, 1, 'avg_spin')\n",
        "    statcast['Year'] = [i] * len(statcast)\n",
        "    for i in range(len(statcast)):\n",
        "      statcast.at[i, 'last_name, first_name'] = fix_name(statcast.at[i,'last_name, first_name'])\n",
        "    if output is None:\n",
        "      output = statcast\n",
        "    else:\n",
        "      output = pd.concat([output, statcast])\n",
        "  return output\n",
        "\n",
        "def merge_sections(season, spin):\n",
        "  season_locs = []\n",
        "  spin_locs = []\n",
        "  for col in import_cols_left:\n",
        "    season_locs.append(season.columns.get_loc(col))\n",
        "  for col in import_cols_right:\n",
        "    spin_locs.append(spin.columns.get_loc(col))\n",
        "  season = season.drop(season.columns[[x for x in range(len(season.columns)) if x not in season_locs]], axis=1)\n",
        "  spin = spin.drop(spin.columns[[x for x in range(len(spin.columns)) if x not in spin_locs]], axis=1)\n",
        "  merged = pd.merge(season, spin, how='outer', left_on = ['Name', 'Season'], right_on = ['last_name, first_name', 'Year'])\n",
        "  merged = merged.drop(merged.columns[[merged.columns.get_loc('Season'), merged.columns.get_loc('Name'),\n",
        "                                       merged.columns.get_loc('Year'), merged.columns.get_loc('last_name, first_name')]], axis=1)\n",
        "  return merged\n",
        "\n",
        "def aggregate_merged(merged):\n",
        "  maxVelo = []\n",
        "  medAvrVelo = []\n",
        "  slowVelo = []\n",
        "  avrSpin = []\n",
        "  med_vars = ['SLv', 'CTv', 'SFv']\n",
        "  slow_vars = ['CBv', 'CHv', 'KNv']\n",
        "  spin_vars = ['ff_avg_spin', 'si_avg_spin', 'fc_avg_spin', 'sl_avg_spin',\n",
        "                     'ch_avg_spin', 'cu_avg_spin']\n",
        "  for index, row in merged.iterrows():\n",
        "    max = row['FBv']\n",
        "    tot_med = 0\n",
        "    count_med = 0\n",
        "    for var in med_vars:\n",
        "      if ~np.isnan(row[var]):\n",
        "        tot_med += row[var]\n",
        "        count_med += 1\n",
        "        if np.isnan(max) or max < row[var]:\n",
        "          max = row[var]\n",
        "    tot_slow = 0\n",
        "    count_slow = 0\n",
        "    for var in slow_vars:\n",
        "      if ~np.isnan(row[var]):\n",
        "        tot_slow += row[var]\n",
        "        count_slow += 1\n",
        "    tot_spin = 0\n",
        "    count_spin = 0\n",
        "    for var in spin_vars:\n",
        "      if ~np.isnan(row[var]):\n",
        "        tot_spin += row[var]\n",
        "        count_spin += 1\n",
        "    maxVelo.append(max)\n",
        "    if count_med != 0:\n",
        "      medAvrVelo.append(tot_med/count_med)\n",
        "    else:\n",
        "      medAvrVelo.append(np.nan)\n",
        "    if count_slow != 0:\n",
        "      slowVelo.append(tot_slow/count_slow)\n",
        "    else:\n",
        "      slowVelo.append(np.nan)\n",
        "    if count_spin != 0:\n",
        "      avrSpin.append(tot_spin/count_spin)\n",
        "    else:\n",
        "      avrSpin.append(np.nan)\n",
        "  merged['MaxVelo'] = maxVelo\n",
        "  merged['AvgMedVelo'] = medAvrVelo\n",
        "  merged['AvgSlowVelo'] = slowVelo\n",
        "  merged['AvgSpin'] = avrSpin\n",
        "  to_drop = ['FBv','SL%', 'SLv', 'CT%', 'CTv', 'CB%', 'CBv', 'CH%', 'CHv',\n",
        "             'SF%', 'SFv', 'KN%', 'KNv', 'ff_avg_spin', 'si_avg_spin',\n",
        "             'fc_avg_spin', 'sl_avg_spin', 'ch_avg_spin', 'cu_avg_spin']\n",
        "  for drop in to_drop:\n",
        "    merged = merged.drop(merged.columns[[merged.columns.get_loc(drop)]], axis=1)\n",
        "  return merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb2c90b",
      "metadata": {
        "id": "6eb2c90b"
      },
      "outputs": [],
      "source": [
        "ucl_injuries = build_ucl_injuries()\n",
        "season_tots = add_ucl_injuries_to_table(ucl_injuries)\n",
        "spin = get_spin()\n",
        "merged = merge_sections(season_tots, spin)\n",
        "merged = aggregate_merged(merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d32267",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d32267",
        "outputId": "5aa41147-9880-4850-bd02-2e5e9de3a2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Age     G   GS   CG    IP  Pitches  K/BB    FB%  Zone%  F-Strike%  \\\n",
            "4927  30.0  14.0  8.0  0.0  47.2    966.0  1.50  0.508  0.411      0.517   \n",
            "4928  27.0  15.0  0.0  0.0  11.2    217.0  1.00  0.675  0.378      0.474   \n",
            "4930  29.0  38.0  1.0  0.0  56.1   1014.0  1.63  0.517  0.363      0.518   \n",
            "4931  25.0  29.0  7.0  0.0  66.0   1037.0  1.43  0.373  0.429      0.511   \n",
            "4932  33.0  32.0  9.0  0.0  70.1   1185.0  3.83  0.453  0.435      0.626   \n",
            "\n",
            "         K%    BB%  MaxVelo  AvgMedVelo  AvgSlowVelo      AvgSpin  \n",
            "4927  0.140  0.093     90.3       83.70        80.20  2322.800000  \n",
            "4928  0.140  0.140     95.5       90.60        86.15  2058.400000  \n",
            "4930  0.173  0.106     91.6       85.65        77.00  2505.500000  \n",
            "4931  0.144  0.101     92.1       85.10        85.70  2152.666667  \n",
            "4932  0.143  0.037     87.8       85.90        79.10  2279.600000  \n"
          ]
        }
      ],
      "source": [
        "merged_no_nan = merged.dropna()\n",
        "Y = merged_no_nan['UCL_Injury']\n",
        "X = merged_no_nan.drop(merged.columns[[merged.columns.get_loc('UCL_Injury')]], axis=1)\n",
        "print(X.tail())\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, train_size = 0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49eda9d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49eda9d0",
        "outputId": "aae96f9d-874c-40bf-b1f6-bd0e76d45a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9696969696969697\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98       643\n",
            "         1.0       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.97       660\n",
            "   macro avg       0.49      0.50      0.49       660\n",
            "weighted avg       0.95      0.97      0.96       660\n",
            "\n",
            "Cross-validation Scores: [0.96969697 0.96969697 0.96212121 0.96590909 0.96590909]\n",
            "Mean CV Accuracy: 0.9666666666666666\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "def get_best_k():\n",
        "\n",
        "  K = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "  errTrain = [0] * 8\n",
        "  errTest = [0] * 8\n",
        "\n",
        "  for i, k in enumerate(K):\n",
        "    neighbors = KNeighborsClassifier(n_neighbors = k)\n",
        "    model = neighbors.fit(X_train, Y_train)\n",
        "    Y_test_pred = neighbors.predict(X_test)\n",
        "    Y_train_pred = neighbors.predict(X_train)\n",
        "    errTrain[i] = log_loss(Y_train, Y_train_pred)\n",
        "    errTest[i] = log_loss(Y_test, Y_test_pred)\n",
        "  plt.plot(K, errTrain, K, errTest)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "cv_scores = cross_val_score(knn, X_train, Y_train, cv=5)\n",
        "\n",
        "knn.fit(X_train.values, Y_train.values)\n",
        "\n",
        "Y_test_pred = knn.predict(X_test.values)\n",
        "\n",
        "accuracy = accuracy_score(Y_test.values, Y_test_pred)\n",
        "report = classification_report(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Cross-validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d14cbee6",
      "metadata": {
        "id": "d14cbee6"
      },
      "outputs": [],
      "source": [
        "Y = merged_no_nan['UCL_Injury']\n",
        "X = merged_no_nan.drop(merged.columns[[merged.columns.get_loc('UCL_Injury')]], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, train_size = 0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bcb1bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13bcb1bc",
        "outputId": "a2f65b56-de6a-4b8f-9192-f8a1a51cbd7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9636363636363636\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98       636\n",
            "         1.0       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.96       660\n",
            "   macro avg       0.48      0.50      0.49       660\n",
            "weighted avg       0.93      0.96      0.95       660\n",
            "\n",
            "Cross-validation Scores: [0.97159091 0.97159091 0.97159091 0.97159091 0.96969697]\n",
            "Mean CV Accuracy: 0.9712121212121211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "cv_scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "report = classification_report(Y_test, Y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Cross-validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ab5312",
      "metadata": {
        "id": "c7ab5312"
      },
      "outputs": [],
      "source": [
        "Y = merged_no_nan['UCL_Injury']\n",
        "X = merged_no_nan.drop(merged.columns[[merged.columns.get_loc('UCL_Injury')]], axis=1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, train_size = 0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e171d538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e171d538",
        "outputId": "0e353383-6f0c-47d6-d060-6cf80c6d9b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Classifier Test Accuracy: 0.9651515151515152\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98       637\n",
            "         1.0       0.00      0.00      0.00        23\n",
            "\n",
            "    accuracy                           0.97       660\n",
            "   macro avg       0.48      0.50      0.49       660\n",
            "weighted avg       0.93      0.97      0.95       660\n",
            "\n",
            "Cross-validation Scores: [0.97159091 0.97159091 0.89393939 0.90340909 0.96969697]\n",
            "Mean CV Accuracy: 0.9420454545454545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=300)\n",
        "\n",
        "cv_scores = cross_val_score(mlp, X_train, Y_train, cv=5)\n",
        "\n",
        "mlp.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = mlp.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "report = classification_report(Y_test, Y_pred)\n",
        "\n",
        "print(\"MLP Classifier Test Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Cross-validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdedabc4",
      "metadata": {
        "id": "bdedabc4"
      },
      "outputs": [],
      "source": [
        "Y = merged_no_nan['UCL_Injury']\n",
        "X = merged_no_nan.drop(merged.columns[[merged.columns.get_loc('UCL_Injury')]], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b23105",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9b23105",
        "outputId": "301fd818-5bd2-4b25-812f-355ef0fb97e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hanvi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "Score for fold 1: loss of 0.13414266705513; accuracy of 0.9727272987365723\n",
            "Score for fold 2: loss of 0.1323796659708023; accuracy of 0.9681817889213562\n",
            "Score for fold 3: loss of 0.10502452403306961; accuracy of 0.9742424488067627\n",
            "Score for fold 4: loss of 0.11029192805290222; accuracy of 0.9772727489471436\n",
            "Score for fold 5: loss of 0.18720777332782745; accuracy of 0.9560605883598328\n",
            "\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9696969747543335 (+- 0.007422713444929223)\n",
            "> Loss: 0.13380931168794633\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "Y_categorical = to_categorical(Y)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = np.expand_dims(X_scaled[train_index], -1), np.expand_dims(X_scaled[test_index], -1)\n",
        "    Y_train, Y_test = Y_categorical[train_index], Y_categorical[test_index]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
        "\n",
        "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
        "    acc_per_fold.append(scores[1])\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "print('\\nAverage scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20897a4",
      "metadata": {
        "id": "e20897a4",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_game_codes():\n",
        "    all_games = []\n",
        "    for i in range(2022, 2024):\n",
        "        response = requests.get(f'https://statsapi.mlb.com/api/v1/schedule?sportId=1&startDate={i}-01-01&endDate={i}-12-31&gameType=R&fields=dates,date,games,gamePk')\n",
        "        json = response.json()\n",
        "        for date in json['dates']:\n",
        "            for game in date['games']:\n",
        "                all_games.append(game['gamePk'])\n",
        "    return all_games\n",
        "\n",
        "fields = ['release_speed', 'release_pos_x', 'release_pos_y']\n",
        "pitcher_logs = {}\n",
        "\n",
        "def injured_year(player, year):\n",
        "      output = pb.playerid_reverse_lookup([player], key_type='mlbam')\n",
        "      name = remove_accents(output.iloc[0]['name_first']) + ' ' + remove_accents(output.iloc[0]['name_last'])\n",
        "      for index, row in ucl_injuries[ucl_injuries.Year == year].iterrows():\n",
        "        if row['Name'].lower() == name:\n",
        "          return 1\n",
        "      return 0\n",
        "\n",
        "def update_game_by_game():\n",
        "\n",
        "    def convert_to_dataframe(name, pitch):\n",
        "        output = {'pitch_name': name, **pitch}\n",
        "        for field in output:\n",
        "            output[field] = [output[field]]\n",
        "        #print(DataFrame(output.update(pitch)))\n",
        "        return DataFrame.from_dict(output)\n",
        "\n",
        "    codes = get_game_codes()\n",
        "    fields = ['release_speed', 'release_pos_x', 'release_pos_y']\n",
        "    for code in codes:\n",
        "        game = None\n",
        "        try:\n",
        "          game = pb.statcast_single_game(code)\n",
        "        except:\n",
        "          continue\n",
        "        if game is None:\n",
        "            continue\n",
        "        pitchers = {}\n",
        "        for index, row in game.iterrows():\n",
        "            if row['pitcher'] in pitchers:\n",
        "                if row['pitch_name'] in pitchers[row['pitcher']]:\n",
        "                    for field in fields:\n",
        "                        pitchers[row['pitcher']][row['pitch_name']][field] += row[field]\n",
        "                    pitchers[row['pitcher']][row['pitch_name']]['pitch_num'] += 1\n",
        "                else:\n",
        "                    pitchers[row['pitcher']][row['pitch_name']] = {'pitch_num': 1}\n",
        "                    pitchers[row['pitcher']][row['pitch_name']]['pitch_type'] = row['pitch_type']\n",
        "                    pitchers[row['pitcher']][row['pitch_name']]['game_date'] = row['game_date']\n",
        "                    pitchers[row['pitcher']][row['pitch_name']]['injured'] = pitchers[row['pitcher']][list(pitchers[row['pitcher']].keys())[0]]['injured']\n",
        "                    pitchers[row['pitcher']][row['pitch_name']] = {**pitchers[row['pitcher']][row['pitch_name']], **{field: row[field] for field in fields}}\n",
        "            else:\n",
        "                pitchers[row['pitcher']] = {row['pitch_name']: {'pitch_num': 1}}\n",
        "                pitchers[row['pitcher']][row['pitch_name']]['pitch_type'] = row['pitch_type']\n",
        "                pitchers[row['pitcher']][row['pitch_name']]['game_date'] = row['game_date']\n",
        "                pitchers[row['pitcher']][row['pitch_name']]['injured'] = injured_year(row['pitcher'], get_injury_year(row['game_date']))\n",
        "                pitchers[row['pitcher']][row['pitch_name']] = {**pitchers[row['pitcher']][row['pitch_name']], **{field: row[field] for field in fields}}\n",
        "\n",
        "        for pitcher in pitchers:\n",
        "            for pitch in pitchers[pitcher]:\n",
        "                for field in fields:\n",
        "                    pitchers[pitcher][pitch][field] /= pitchers[pitcher][pitch]['pitch_num']\n",
        "\n",
        "        for pitcher in pitchers:\n",
        "            if pitcher not in pitcher_logs:\n",
        "                pitcher_logs[pitcher] = None\n",
        "                for pitch in pitchers[pitcher]:\n",
        "                    if pitcher_logs[pitcher] is None:\n",
        "                        pitcher_logs[pitcher] = convert_to_dataframe(pitch, pitchers[pitcher][pitch])\n",
        "                    else:\n",
        "                        pitcher_logs[pitcher] = pd.concat([pitcher_logs[pitcher], convert_to_dataframe(pitch, pitchers[pitcher][pitch])])\n",
        "            else:\n",
        "                for pitch in pitchers[pitcher]:\n",
        "                    pitcher_logs[pitcher]= pd.concat([pitcher_logs[pitcher], convert_to_dataframe(pitch, pitchers[pitcher][pitch])])\n",
        "\n",
        "#update_game_by_game()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1hF3ha18S207",
      "metadata": {
        "id": "1hF3ha18S207"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "##!mkdir -p \"/content/drive/My Drive/pitcher_data\"\n",
        "\n",
        "##print(pitcher_logs[list(pitcher_logs.keys())[0]].head())\n",
        "\n",
        "def save_pitchers():\n",
        "  with open('pitcher_data/pitcher_list.txt', 'w') as w:\n",
        "    for pitcher in pitcher_logs:\n",
        "      pitcher_logs[pitcher].to_csv(f'pitcher_data/{pitcher}.csv', index=False)\n",
        "      w.write(str(pitcher) + '\\n')\n",
        "\n",
        "def fix_injuries():\n",
        "  for pitcher in pitcher_logs:\n",
        "    count = 0\n",
        "    for index, row in pitcher_logs[pitcher].iterrows():\n",
        "      pitcher_logs[pitcher].at[count, 'injured'] = injured_year(pitcher, get_injury_year(pd.to_datetime(row['game_date'], format='%Y-%m-%d')))\n",
        "      count += 1\n",
        "\n",
        "#save_pitchers()\n",
        "\n",
        "def load_pitchers():\n",
        "  with open('pitcher_data/pitcher_list.txt', 'r') as r:\n",
        "    for pitcher in r:\n",
        "      pitcher_logs[int(pitcher[:-1])] = pd.read_csv(Path(f'pitcher_data/{pitcher[:-1]}.csv'))\n",
        "\n",
        "def load_delta():\n",
        "  with open('pitcher_data/pitcher_list.txt', 'r') as r:\n",
        "    for pitcher in r:\n",
        "      pitcher_logs[int(pitcher[:-1])] = pd.read_csv(Path(f'pitcher_delta/{pitcher[:-1]}.csv'))\n",
        "\n",
        "def first_occurence(dataframe, pitch, date):\n",
        "  counter = 0\n",
        "  for index, row in dataframe.iterrows():\n",
        "    if row['pitch_name'] == pitch and row['game_date'] != date:\n",
        "      return counter\n",
        "    counter += 1\n",
        "  return -1\n",
        "\n",
        "def calc_difference(dataframe, row, firstIndex):\n",
        "  tot_fields = ['pitch_num'] + fields\n",
        "  if firstIndex == -1:\n",
        "    return DataFrame({'pitch_name': [row['pitch_name']], 'injured': [row['injured']], 'game_date': [0],\n",
        "                      **{field: [0] for field in tot_fields}})\n",
        "  return DataFrame({'pitch_name': [row['pitch_name']], 'injured': [row['injured']],\n",
        "                    'game_date': [(pd.to_datetime(row['game_date'], format='%Y-%m-%d')-pd.to_datetime(dataframe.iloc[firstIndex]['game_date'], format='%Y-%m-%d')).days],\n",
        "                    **{field: [float(row[field]) - float(dataframe.iloc[firstIndex][field])] for field in tot_fields}})\n",
        "\n",
        "def update_to_delta():\n",
        "  for pitcher in pitcher_logs:\n",
        "    new = None\n",
        "    reversed = pitcher_logs[pitcher].iloc[::-1]\n",
        "    while len(reversed) > 0:\n",
        "      temp = reversed.iloc[0]\n",
        "      reversed = reversed.iloc[1:, :]\n",
        "      if new is None:\n",
        "        new = calc_difference(reversed, temp, first_occurence(reversed, temp['pitch_name'], temp['game_date']))\n",
        "      else:\n",
        "        new = pd.concat([new, calc_difference(reversed, temp, first_occurence(reversed, temp['pitch_name'], temp['game_date']))])\n",
        "    pitcher_logs[pitcher] = new[::-1]\n",
        "\n",
        "def save_delta():\n",
        "  #!mkdir -p \"/content/drive/MyDrive/pitcher_delta\"\n",
        "  for pitcher in pitcher_logs:\n",
        "    if type(pitcher) == str:\n",
        "      pitcher_logs[int(pitcher[:-1])].to_csv(f'pitcher_delta/{int(pitcher[:-1])}.csv', index=False)\n",
        "    else:\n",
        "      pitcher_logs[pitcher].to_csv(f'pitcher_delta/{pitcher}.csv', index=False)\n",
        "\n",
        "def drop_na():\n",
        "  to_drop = ['spin_dir', 'spin_rate_deprecated', 'break_angle_deprecated', 'break_length_deprecated']\n",
        "  for pitcher in pitcher_logs:\n",
        "    for drop in to_drop:\n",
        "      pitcher_logs[pitcher] = pitcher_logs[pitcher].drop(pitcher_logs[pitcher].columns[[pitcher_logs[pitcher].columns.get_loc(drop)]], axis=1)\n",
        "\n",
        "#update_to_delta()\n",
        "#ucl_injuries = build_ucl_injuries()\n",
        "load_pitchers()\n",
        "fix_injuries()\n",
        "\n",
        "#save_delta()\n",
        "#load_delta()\n",
        "drop_na()\n",
        "\n",
        "#print(pitcher_logs[660271])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0cb13e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cd0cb13e",
        "outputId": "3b8eff4d-b1ad-494b-e0de-228352f6aec4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitch_name</th>\n",
              "      <th>pitch_num</th>\n",
              "      <th>pitch_type</th>\n",
              "      <th>game_date</th>\n",
              "      <th>injured</th>\n",
              "      <th>release_speed</th>\n",
              "      <th>release_pos_x</th>\n",
              "      <th>release_pos_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sweeper</td>\n",
              "      <td>22</td>\n",
              "      <td>ST</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>0</td>\n",
              "      <td>84.909091</td>\n",
              "      <td>-2.239091</td>\n",
              "      <td>53.616818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4-Seam Fastball</td>\n",
              "      <td>35</td>\n",
              "      <td>FF</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>0</td>\n",
              "      <td>97.751429</td>\n",
              "      <td>-2.084286</td>\n",
              "      <td>53.575714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cutter</td>\n",
              "      <td>1</td>\n",
              "      <td>FC</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>0</td>\n",
              "      <td>91.500000</td>\n",
              "      <td>-2.220000</td>\n",
              "      <td>53.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Split-Finger</td>\n",
              "      <td>11</td>\n",
              "      <td>FS</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>0</td>\n",
              "      <td>90.518182</td>\n",
              "      <td>-1.886364</td>\n",
              "      <td>53.499091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Curveball</td>\n",
              "      <td>11</td>\n",
              "      <td>CU</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>0</td>\n",
              "      <td>78.590909</td>\n",
              "      <td>-1.707273</td>\n",
              "      <td>53.672727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>4-Seam Fastball</td>\n",
              "      <td>7</td>\n",
              "      <td>FF</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>1</td>\n",
              "      <td>93.242857</td>\n",
              "      <td>-1.834286</td>\n",
              "      <td>53.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>Sweeper</td>\n",
              "      <td>9</td>\n",
              "      <td>ST</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>1</td>\n",
              "      <td>78.977778</td>\n",
              "      <td>-2.102222</td>\n",
              "      <td>53.882222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>Split-Finger</td>\n",
              "      <td>7</td>\n",
              "      <td>FS</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>1</td>\n",
              "      <td>87.871429</td>\n",
              "      <td>-1.728571</td>\n",
              "      <td>53.671429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>Curveball</td>\n",
              "      <td>2</td>\n",
              "      <td>CU</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>1</td>\n",
              "      <td>69.950000</td>\n",
              "      <td>-1.620000</td>\n",
              "      <td>53.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>Cutter</td>\n",
              "      <td>1</td>\n",
              "      <td>FC</td>\n",
              "      <td>2023-08-23</td>\n",
              "      <td>1</td>\n",
              "      <td>84.900000</td>\n",
              "      <td>-2.040000</td>\n",
              "      <td>53.760000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>282 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          pitch_name  pitch_num pitch_type   game_date  injured  \\\n",
              "0            Sweeper         22         ST  2022-04-07        0   \n",
              "1    4-Seam Fastball         35         FF  2022-04-07        0   \n",
              "2             Cutter          1         FC  2022-04-07        0   \n",
              "3       Split-Finger         11         FS  2022-04-07        0   \n",
              "4          Curveball         11         CU  2022-04-07        0   \n",
              "..               ...        ...        ...         ...      ...   \n",
              "277  4-Seam Fastball          7         FF  2023-08-23        1   \n",
              "278          Sweeper          9         ST  2023-08-23        1   \n",
              "279     Split-Finger          7         FS  2023-08-23        1   \n",
              "280        Curveball          2         CU  2023-08-23        1   \n",
              "281           Cutter          1         FC  2023-08-23        1   \n",
              "\n",
              "     release_speed  release_pos_x  release_pos_y  \n",
              "0        84.909091      -2.239091      53.616818  \n",
              "1        97.751429      -2.084286      53.575714  \n",
              "2        91.500000      -2.220000      53.360000  \n",
              "3        90.518182      -1.886364      53.499091  \n",
              "4        78.590909      -1.707273      53.672727  \n",
              "..             ...            ...            ...  \n",
              "277      93.242857      -1.834286      53.642857  \n",
              "278      78.977778      -2.102222      53.882222  \n",
              "279      87.871429      -1.728571      53.671429  \n",
              "280      69.950000      -1.620000      53.950000  \n",
              "281      84.900000      -2.040000      53.760000  \n",
              "\n",
              "[282 rows x 8 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pitcher_logs[660271]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d817a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00d817a9",
        "outputId": "7c03bab4-bb21-42bd-bcc5-acf68a0af16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score for fold 1: loss of 0.0867636427283287; accuracy of 0.9828453063964844\n",
            "Score for fold 11: loss of 0.08760438114404678; accuracy of 0.9826343655586243\n",
            "Score for fold 21: loss of 0.08603768050670624; accuracy of 0.983021080493927\n",
            "Score for fold 31: loss of 0.08533437550067902; accuracy of 0.9831967949867249\n",
            "Score for fold 41: loss of 0.09088271856307983; accuracy of 0.9818252325057983\n",
            "\n",
            "Average scores for all folds:\n",
            "> Accuracy: 0.9827045559883117 (+- 0.0004775843705427766)\n",
            "> Loss: 0.08732455968856812\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_pitcher_data = pd.concat(pitcher_logs.values())\n",
        "\n",
        "features = all_pitcher_data.drop(['injured', 'pitch_name', 'pitch_type', 'game_date'], axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "target = all_pitcher_data['injured']\n",
        "target = to_categorical(target)\n",
        "\n",
        "num_samples = scaled_features.shape[0]\n",
        "num_timesteps = 1\n",
        "num_features = scaled_features.shape[1]\n",
        "scaled_features = scaled_features.reshape((num_samples, num_timesteps, num_features))\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train_index, test_index in kf.split(scaled_features):\n",
        "    X_train, X_test = scaled_features[train_index], scaled_features[test_index]\n",
        "    Y_train, Y_test = target[train_index], target[test_index]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(50, input_shape=(num_timesteps, num_features), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(SimpleRNN(50, return_sequences=False))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(target.shape[1], activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test), verbose=0)\n",
        "\n",
        "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
        "    acc_per_fold.append(scores[1])\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_no += 10\n",
        "\n",
        "print('\\nAverage scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9677977f",
      "metadata": {
        "id": "9677977f"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'pitcher_data.zip'  # Replace with your zip file path\n",
        "extract_path = 'pitcher_data'  # Replace with the desired extraction path\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5edd8e9",
      "metadata": {
        "id": "a5edd8e9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}